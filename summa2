import boto3
import csv

# Initialize the S3 client
s3_client = boto3.client('s3')

# Specify the CSV output file path
output_csv_file = 's3_subfolder_structure.csv'

def list_subfolders(bucket_name, prefix=''):
    subfolder_paths = []

    # List objects in the bucket, with the specified prefix (subfolder)
    objects_response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')

    # Iterate through common prefixes (subfolders)
    for prefix in objects_response.get('CommonPrefixes', []):
        subfolder_name = prefix['Prefix']
        subfolder_paths.append(subfolder_name)
        subfolder_paths.extend(list_subfolders(bucket_name, prefix=subfolder_name))  # Recurse into subfolders

    return subfolder_paths

try:
    # Get the list of all S3 buckets in the account
    bucket_response = s3_client.list_buckets()

    # Prepare the CSV file for writing
    with open(output_csv_file, 'w', newline='') as csv_file:
        fieldnames = ['Bucket Name', 'Subfolder Structure']
        csv_writer = csv.writer(csv_file)
        csv_writer.writerow(fieldnames)

        # Iterate through each bucket
        for bucket in bucket_response['Buckets']:
            bucket_name = bucket['Name']

            # List all subfolders recursively
            subfolder_paths = list_subfolders(bucket_name)

            # Write bucket name and subfolder paths to CSV
            if subfolder_paths:
                for path in subfolder_paths:
                    csv_writer.writerow([bucket_name, path])
            else:
                csv_writer.writerow([bucket_name, 'No folder exists'])

    print("CSV output written to", output_csv_file)

except Exception as e:
    print("Error:", e)
