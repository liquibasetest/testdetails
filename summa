import numpy as np
from sklearn.cluster import DBSCAN

# Generate synthetic data: normal response times
normal_response_times = np.random.normal(loc=0.5, scale=0.1, size=100)

print(normal_response_times)
print('outlier response time')
# Generate synthetic data: outliers (abnormal response times)
outliers = np.random.uniform(low=0, high=1, size=30)
print(outliers)

print('combined response time')
# Combine normal and outlier response times
response_times = np.concatenate((normal_response_times, outliers))

print(response_times)


[0.6520234  0.41436496 0.40622846 0.57098262 0.36214057 0.42467231
 0.52571048 0.69624721 0.55141514 0.49057543 0.57248852 0.58922577
 0.48171991 0.50960964 0.71360226 0.59017121 0.66330964 0.66463757
 0.38990994 0.66402725 0.39798172 0.49539002 0.40196013 0.40752738
 0.65489316 0.59860134 0.64923324 0.50943639 0.55910588 0.52473617
 0.48024062 0.22216297 0.71331395 0.6157151  0.55758524 0.41973822
 0.33187757 0.46766712 0.3788293  0.52882607 0.62310961 0.55491103
 0.7026195  0.52062733 0.70387722 0.59612811 0.48570582 0.73052475
 0.62479249 0.4728267  0.62212751 0.47594262 0.3716462  0.49236868
 0.48783764 0.37486706 0.38448845 0.57171697 0.48070436 0.57727684
 0.45642486 0.45320313 0.40154322 0.4125557  0.36875688 0.53121919
 0.6029563  0.34803713 0.42582912 0.5913128  0.56957544 0.4346999
 0.4347871  0.47937928 0.69659383 0.27756476 0.72247357 0.54201884
 0.55368715 0.39146637 0.57398927 0.35407585 0.52524248 0.49529498
 0.39514783 0.41511913 0.63525536 0.4294078  0.62863516 0.50170097
 0.56771182 0.65900999 0.62895193 0.38104247 0.57838747 0.66628866
 0.62007006 0.49450025 0.65131358 0.51014893]
outlier response time
[0.43768429 0.98093263 0.26391356 0.73019645 0.70924896 0.21504337
 0.77840798 0.56396247 0.79314425 0.67817581 0.25800494 0.59374807
 0.84091077 0.70158569 0.00949819 0.72406859 0.71026383 0.34399754
 0.57016451 0.56882804 0.52352063 0.47213215 0.74556149 0.99349716
 0.10158467 0.78599238 0.01923394 0.24443049 0.97322768 0.26172279]
combined response time
[0.6520234  0.41436496 0.40622846 0.57098262 0.36214057 0.42467231
 0.52571048 0.69624721 0.55141514 0.49057543 0.57248852 0.58922577
 0.48171991 0.50960964 0.71360226 0.59017121 0.66330964 0.66463757
 0.38990994 0.66402725 0.39798172 0.49539002 0.40196013 0.40752738
 0.65489316 0.59860134 0.64923324 0.50943639 0.55910588 0.52473617
 0.48024062 0.22216297 0.71331395 0.6157151  0.55758524 0.41973822
 0.33187757 0.46766712 0.3788293  0.52882607 0.62310961 0.55491103
 0.7026195  0.52062733 0.70387722 0.59612811 0.48570582 0.73052475
 0.62479249 0.4728267  0.62212751 0.47594262 0.3716462  0.49236868
 0.48783764 0.37486706 0.38448845 0.57171697 0.48070436 0.57727684
 0.45642486 0.45320313 0.40154322 0.4125557  0.36875688 0.53121919
 0.6029563  0.34803713 0.42582912 0.5913128  0.56957544 0.4346999
 0.4347871  0.47937928 0.69659383 0.27756476 0.72247357 0.54201884
 0.55368715 0.39146637 0.57398927 0.35407585 0.52524248 0.49529498
 0.39514783 0.41511913 0.63525536 0.4294078  0.62863516 0.50170097
 0.56771182 0.65900999 0.62895193 0.38104247 0.57838747 0.66628866
 0.62007006 0.49450025 0.65131358 0.51014893 0.43768429 0.98093263
 0.26391356 0.73019645 0.70924896 0.21504337 0.77840798 0.56396247
 0.79314425 0.67817581 0.25800494 0.59374807 0.84091077 0.70158569
 0.00949819 0.72406859 0.71026383 0.34399754 0.57016451 0.56882804
 0.52352063 0.47213215 0.74556149 0.99349716 0.10158467 0.78599238
 0.01923394 0.24443049 0.97322768 0.26172279]
 
 
data = response_times.reshape(-1, 1)
print(type(data))
print(data)

#The original response_times array is a one-dimensional array with 5 elements.
#When you call .reshape(-1, 1), you're instructing NumPy to create a new array with an unknown number of rows (-1 in the first dimension) and exactly 1 column (1 in the second dimension).
#NumPy automatically infers that since you want 1 column, each element of the original array should occupy its own row in the new array.

[0.49236868]
 [0.48783764]
 [0.37486706]
 [0.38448845]
 [0.57171697]
 [0.48070436]
 [0.57727684]
 [0.45642486]
 [0.45320313]
 [0.40154322]
 [0.4125557 ]
 [0.36875688]
 [0.53121919]
 [0.6029563 ]
 [0.34803713]
 [0.42582912]
 [0.5913128 ]
 [0.56957544]
 [0.4346999 ]
 [0.4347871 ]
 [0.47937928]
 [0.69659383]
 [0.27756476]
 [0.72247357]
 [0.54201884]
 [0.55368715]
 [0.39146637]
 [0.57398927]
 [0.35407585]
 [0.52524248]
 [0.49529498]
 [0.39514783]
 [0.41511913]
 [0.63525536]
 [0.4294078 ]
 [0.62863516]
 [0.50170097]
 [0.56771182]
 [0.65900999]
 [0.62895193]
 [0.38104247]
 [0.57838747]
 [0.66628866]
 [0.62007006]
 [0.49450025]
 [0.65131358]
 [0.51014893]
 [0.43768429]
 [0.98093263]
 [0.26391356]
 [0.73019645]
 [0.70924896]
 [0.21504337]
 [0.77840798]
 [0.56396247]
 [0.79314425]
 [0.67817581]
 [0.25800494]
 [0.59374807]
 [0.84091077]
 [0.70158569]
 [0.00949819]
 [0.72406859]
 [0.71026383]
 [0.34399754]
 [0.57016451]
 [0.56882804]
 [0.52352063]
 [0.47213215]
 [0.74556149]
 [0.99349716]
 [0.10158467]
 [0.78599238]
 [0.01923394]
 [0.24443049]
 [0.97322768]
 [0.26172279]]

from sklearn.cluster import DBSCAN

# Create a DBSCAN model
dbscan = DBSCAN(eps=0.1, min_samples=5)

[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0
  0  0  0 -1 -1  0 -1  0 -1  0]


# Fit the model to the data
labels = dbscan.fit_predict(data)
print(labels)

Identified Outliers:
 [[0.6520234 ]
 [0.41436496]
 [0.40622846]
 [0.57098262]
 [0.36214057]
 [0.42467231]
 [0.52571048]
 [0.69624721]
 [0.55141514]
 [0.49057543]
 [0.57248852]
 [0.58922577]
 [0.48171991]
 [0.50960964]
 [0.71360226]
 [0.59017121]
 [0.66330964]
 [0.66463757]
 [0.38990994]
 [0.66402725]
 [0.39798172]
 [0.49539002]
 [0.40196013]
 [0.40752738]
 [0.65489316]
 [0.59860134]
 [0.64923324]
 [0.50943639]
 [0.55910588]
 [0.52473617]
 [0.48024062]
 [0.22216297]
 [0.71331395]
 [0.6157151 ]
 [0.55758524]
 [0.41973822]
 [0.33187757]
 [0.46766712]
 [0.3788293 ]
 [0.52882607]
 [0.62310961]
 [0.55491103]
 [0.7026195 ]
 [0.52062733]
 [0.70387722]
 [0.59612811]
 [0.48570582]
 [0.73052475]
 [0.62479249]
 [0.4728267 ]
 [0.62212751]
 [0.47594262]
 [0.3716462 ]
 [0.49236868]
 [0.48783764]
 [0.37486706]
 [0.38448845]
 [0.57171697]
 [0.48070436]
 [0.57727684]
 [0.45642486]
 [0.45320313]
 [0.40154322]
 [0.4125557 ]
 [0.36875688]
 [0.53121919]
 [0.6029563 ]
 [0.34803713]
 [0.42582912]
 [0.5913128 ]
 [0.56957544]
 [0.4346999 ]
 [0.4347871 ]
 [0.47937928]
 [0.69659383]
 [0.27756476]
 [0.72247357]
 [0.54201884]
 [0.55368715]
 [0.39146637]
 [0.57398927]
 [0.35407585]
 [0.52524248]
 [0.49529498]
 [0.39514783]
 [0.41511913]
 [0.63525536]
 [0.4294078 ]
 [0.62863516]
 [0.50170097]
 [0.56771182]
 [0.65900999]
 [0.62895193]
 [0.38104247]
 [0.57838747]
 [0.66628866]
 [0.62007006]
 [0.49450025]
 [0.65131358]
 [0.51014893]
 [0.43768429]
 [0.26391356]
 [0.73019645]
 [0.70924896]
 [0.21504337]
 [0.77840798]
 [0.56396247]
 [0.79314425]
 [0.67817581]
 [0.25800494]
 [0.59374807]
 [0.84091077]
 [0.70158569]
 [0.72406859]
 [0.71026383]
 [0.34399754]
 [0.57016451]
 [0.56882804]
 [0.52352063]
 [0.47213215]
 [0.74556149]
 [0.78599238]
 [0.24443049]
 [0.26172279]]
Identified Outliers:
 [[0.98093263]
 [0.00949819]
 [0.99349716]
 [0.10158467]
 [0.01923394]
 [0.97322768]]


#In this example:

#eps: We set the maximum distance between data points to consider them in the same neighborhood.
#min_samples: The minimum number of samples in a neighborhood to be considered a core point.

#To visualize the results, let's create a scatter plot showing the response times and highlighting the outliers.
import matplotlib.pyplot as plt

plt.scatter(range(len(data)), data, c=labels, cmap='viridis')
plt.xlabel("Data Point Index")
plt.ylabel("Response Time")
plt.title("API Call Response Times with Outliers Detected by DBSCAN")
plt.colorbar(label="Cluster Label")
plt.show()





